{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1G-5p4XiRk4imo92de-ieqhH43X4-J3HD","timestamp":1705939107544},{"file_id":"1aWrx0llmsJZzqlnqVkxvmyX9_dwKbXO2","timestamp":1705938961151},{"file_id":"https://github.com/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb","timestamp":1705936932068}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ebf984b6edd2401682645fdde7ae7177":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_939198dc99e44c518868a0fa20b7b343","IPY_MODEL_050c444a49b241e0a84c7233380ae13f","IPY_MODEL_e74ce68e5dbc4d48817d16a760b45da8"],"layout":"IPY_MODEL_7b0f0a3a10274ef28314fd4517a0ea0d"}},"939198dc99e44c518868a0fa20b7b343":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1de3da66a6eb45718f4b0066aa5858b5","placeholder":"​","style":"IPY_MODEL_547921106de34d6a8646c9d32c66fbae","value":"100%"}},"050c444a49b241e0a84c7233380ae13f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e8a2ccd95fe4715bb574e06e4ac7055","max":19,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4421de13aa604b8d9e258374cfff3512","value":19}},"e74ce68e5dbc4d48817d16a760b45da8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4f3e3f366044ad38b33008bf3c7ace5","placeholder":"​","style":"IPY_MODEL_29dc6f3134874cb784a5f089d1cde2e8","value":" 19/19 [00:17&lt;00:00,  1.15it/s]"}},"7b0f0a3a10274ef28314fd4517a0ea0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1de3da66a6eb45718f4b0066aa5858b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"547921106de34d6a8646c9d32c66fbae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e8a2ccd95fe4715bb574e06e4ac7055":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4421de13aa604b8d9e258374cfff3512":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e4f3e3f366044ad38b33008bf3c7ace5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29dc6f3134874cb784a5f089d1cde2e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"601b31212f9b4ee9900366480e293789":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bd4c5c0acee544aeb9de44f7f01971e2","IPY_MODEL_d12389d3956840648dc7f8ba1e64200d","IPY_MODEL_de49c93253aa493c852a42f5d4baa952"],"layout":"IPY_MODEL_d81c9f44943c4698987dcd433bbe91c1"}},"bd4c5c0acee544aeb9de44f7f01971e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d4679af92c64a5096fa042626f19c0a","placeholder":"​","style":"IPY_MODEL_ea1171927f364f2a9259e21ad04da5c0","value":"100%"}},"d12389d3956840648dc7f8ba1e64200d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_29a6a0f905af4ce1b91d7b64017c7f1a","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf2abd22251848c1aa3e8dc4b7b4a350","value":4}},"de49c93253aa493c852a42f5d4baa952":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_edaffb97c56f45b888b77c646fab2c22","placeholder":"​","style":"IPY_MODEL_14a99aa232c1406ab37d1f206d57aff3","value":" 4/4 [00:03&lt;00:00,  1.12it/s]"}},"d81c9f44943c4698987dcd433bbe91c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d4679af92c64a5096fa042626f19c0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea1171927f364f2a9259e21ad04da5c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29a6a0f905af4ce1b91d7b64017c7f1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf2abd22251848c1aa3e8dc4b7b4a350":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"edaffb97c56f45b888b77c646fab2c22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14a99aa232c1406ab37d1f206d57aff3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"7mGmQbAO5pQb"},"source":["# Setup\n","\n","Pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware."]},{"cell_type":"code","metadata":{"id":"wbvMlHd_QwMG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"01f2da8e-dbe5-4577-afa5-cd1d6adf7448","executionInfo":{"status":"ok","timestamp":1705939527059,"user_tz":-60,"elapsed":6088,"user":{"displayName":"isheanesu mugwagwa","userId":"00412971276279760791"}}},"source":["%pip install ultralytics\n","import ultralytics\n","ultralytics.checks()"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.1.4 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Setup complete ✅ (2 CPUs, 12.7 GB RAM, 26.3/78.2 GB disk)\n"]}]},{"cell_type":"code","metadata":{"id":"zR9ZbuQCH7FX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"77f837e0-6050-49e0-e981-d3ceb6412e79","executionInfo":{"status":"ok","timestamp":1705939540318,"user_tz":-60,"elapsed":9591,"user":{"displayName":"isheanesu mugwagwa","userId":"00412971276279760791"}}},"source":["## importing required libraries\n","import os\n","import shutil\n","import random\n","\n","!pip install tqdm --upgrade\n","from tqdm.notebook import tqdm"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n"]}]},{"cell_type":"code","source":["## connecting to the google drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"xtN3_-BnqPkj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705939563104,"user_tz":-60,"elapsed":21069,"user":{"displayName":"isheanesu mugwagwa","userId":"00412971276279760791"}},"outputId":"151b0bf7-e85e-4d91-dc3a-5e1c510ae739"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["train_path_img = \"./yolo_data/images/train/\"\n","train_path_label = \"./yolo_data/labels/train/\"\n","val_path_img = \"./yolo_data/images/val/\"\n","val_path_label = \"./yolo_data/labels/val/\"\n","test_path = \"./yolo_data/test\""],"metadata":{"id":"rQqLlYRfrxOC","executionInfo":{"status":"ok","timestamp":1705939565310,"user_tz":-60,"elapsed":344,"user":{"displayName":"isheanesu mugwagwa","userId":"00412971276279760791"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["print(os.path.exists('/content/drive/MyDrive/Door_and_window/yolov8_pointcloud/data'))"],"metadata":{"id":"DJIdxHaJrxa9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705939567910,"user_tz":-60,"elapsed":6,"user":{"displayName":"isheanesu mugwagwa","userId":"00412971276279760791"}},"outputId":"6b25ddb0-4bc0-45df-daab-22c0a46b234d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}]},{"cell_type":"code","source":["'''\n","Split the dataset into train and test and creates the train.txt and test.tx with\n","the respective path of the images in each folder\n","'''\n","\n","def train_test_split(path,neg_path=None, split = 0.2):\n","    print(\"------ PROCESS STARTED -------\")\n","\n","\n","    files = list(set([name[:-4] for name in os.listdir(path)])) ## removing duplicate names i.e. counting only number of images\n","\n","\n","    print (f\"--- This folder has a total number of {len(files)} images---\")\n","    random.seed(42)\n","    random.shuffle(files)\n","\n","    test_size = int(len(files) * split)\n","    train_size = len(files) - test_size\n","\n","    ## creating required directories\n","\n","    os.makedirs(train_path_img, exist_ok = True)\n","    os.makedirs(train_path_label, exist_ok = True)\n","    os.makedirs(val_path_img, exist_ok = True)\n","    os.makedirs(val_path_label, exist_ok = True)\n","\n","\n","    ### ----------- copying images to train folder\n","    for filex in tqdm(files[:train_size]):\n","      if filex == 'classes':\n","          continue\n","      shutil.copy2(path + filex + '.jpg',f\"{train_path_img}/\" + filex + '.jpg' )\n","      shutil.copy2(path + filex + '.txt', f\"{train_path_label}/\" + filex + '.txt')\n","\n","\n","\n","    print(f\"------ Training data created with 80% split {len(files[:train_size])} images -------\")\n","\n","    if neg_path:\n","        neg_images = list(set([name[:-4] for name in os.listdir(neg_path)])) ## removing duplicate names i.e. counting only number of images\n","        for filex in tqdm(neg_images):\n","            shutil.copy2(neg_path+filex+ \".jpg\", f\"{train_path_img}/\" + filex + '.jpg')\n","\n","        print(f\"------ Total  {len(neg_images)} negative images added to the training data -------\")\n","\n","        print(f\"------ TOTAL Training data created with {len(files[:train_size]) + len(neg_images)} images -------\")\n","\n","\n","\n","    ### copytin images to validation folder\n","    for filex in tqdm(files[train_size:]):\n","      if filex == 'classes':\n","          continue\n","      # print(\"running\")\n","      shutil.copy2(path + filex + '.jpg', f\"{val_path_img}/\" + filex + '.jpg' )\n","      shutil.copy2(path + filex + '.txt', f\"{val_path_label}/\" + filex + '.txt')\n","\n","    print(f\"------ Testing data created with a total of {len(files[train_size:])} images ----------\")\n","\n","    print(\"------ TASK COMPLETED -------\")\n","\n","## spliting the data into train-test and creating train.txt and test.txt files\n","# train_test_split('/content/drive/MyDrive/custom_notebooks/yolo_data/')\n","\n","### for label_tag\n","train_test_split('/content/drive/MyDrive/Door_and_window/yolov8_pointcloud/data/') ### without negative images\n","# train_test_split('./data/','./negative_images/') ### if you want to feed negative images"],"metadata":{"id":"PTv1e1sJrxid","colab":{"base_uri":"https://localhost:8080/","height":168,"referenced_widgets":["ebf984b6edd2401682645fdde7ae7177","939198dc99e44c518868a0fa20b7b343","050c444a49b241e0a84c7233380ae13f","e74ce68e5dbc4d48817d16a760b45da8","7b0f0a3a10274ef28314fd4517a0ea0d","1de3da66a6eb45718f4b0066aa5858b5","547921106de34d6a8646c9d32c66fbae","4e8a2ccd95fe4715bb574e06e4ac7055","4421de13aa604b8d9e258374cfff3512","e4f3e3f366044ad38b33008bf3c7ace5","29dc6f3134874cb784a5f089d1cde2e8","601b31212f9b4ee9900366480e293789","bd4c5c0acee544aeb9de44f7f01971e2","d12389d3956840648dc7f8ba1e64200d","de49c93253aa493c852a42f5d4baa952","d81c9f44943c4698987dcd433bbe91c1","3d4679af92c64a5096fa042626f19c0a","ea1171927f364f2a9259e21ad04da5c0","29a6a0f905af4ce1b91d7b64017c7f1a","bf2abd22251848c1aa3e8dc4b7b4a350","edaffb97c56f45b888b77c646fab2c22","14a99aa232c1406ab37d1f206d57aff3"]},"executionInfo":{"status":"ok","timestamp":1705939592100,"user_tz":-60,"elapsed":21438,"user":{"displayName":"isheanesu mugwagwa","userId":"00412971276279760791"}},"outputId":"7e4b11de-0116-48f3-b4e4-289be4316972"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["------ PROCESS STARTED -------\n","--- This folder has a total number of 23 images---\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/19 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebf984b6edd2401682645fdde7ae7177"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["------ Training data created with 80% split 19 images -------\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"601b31212f9b4ee9900366480e293789"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["------ Testing data created with a total of 4 images ----------\n","------ TASK COMPLETED -------\n"]}]},{"cell_type":"code","source":["import ultralytics\n","ultralytics.checks()"],"metadata":{"id":"qW0Yxamdrxny","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705939600409,"user_tz":-60,"elapsed":303,"user":{"displayName":"isheanesu mugwagwa","userId":"00412971276279760791"}},"outputId":"4002e6fb-23cf-4db6-9a11-ef130e763900"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.1.4 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Setup complete ✅ (2 CPUs, 12.7 GB RAM, 26.3/78.2 GB disk)\n"]}]},{"cell_type":"markdown","source":["Training"],"metadata":{"id":"pfbKuKXxuR2B"}},{"cell_type":"code","source":["!yolo task=detect mode=train model=yolov8s.pt data=/content/drive/MyDrive/Door_and_window/yolov8_pointcloud/dataset.yaml epochs=150 imgsz=640 batch=8 project=/content/drive/MyDrive/Door_and_window/yolov8_pointcloud/training_results name=door_and_window"],"metadata":{"id":"hx3aPwDlrxrB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705939736302,"user_tz":-60,"elapsed":133965,"user":{"displayName":"isheanesu mugwagwa","userId":"00412971276279760791"}},"outputId":"93b74474-9f7a-4236-955f-b4025f6940cf"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8s.pt to 'yolov8s.pt'...\n","100% 21.5M/21.5M [00:00<00:00, 278MB/s]\n","Ultralytics YOLOv8.1.4 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/drive/MyDrive/Door_and_window/yolov8_pointcloud/dataset.yaml, epochs=150, time=None, patience=50, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/drive/MyDrive/Door_and_window/yolov8_pointcloud/training_results, name=door_and_window, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/Door_and_window/yolov8_pointcloud/training_results/door_and_window\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","100% 755k/755k [00:00<00:00, 49.5MB/s]\n","2024-01-22 16:06:49.826838: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-01-22 16:06:49.826899: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-01-22 16:06:49.828291: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","Overriding model.yaml nc=80 with nc=2\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n","Model summary: 225 layers, 11136374 parameters, 11136358 gradients, 28.6 GFLOPs\n","\n","Transferred 349/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/training_results/door_and_window', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n","100% 6.23M/6.23M [00:00<00:00, 188MB/s]\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo_data/labels/train... 19 images, 0 backgrounds, 0 corrupt: 100% 19/19 [00:00<00:00, 748.29it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolo_data/labels/train.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_data/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100% 4/4 [00:00<00:00, 769.77it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo_data/labels/val.cache\n","Plotting labels to /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/training_results/door_and_window/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/content/drive/MyDrive/Door_and_window/yolov8_pointcloud/training_results/door_and_window\u001b[0m\n","Starting training for 150 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      1/150      2.27G      1.137      3.607      1.352          6        640: 100% 3/3 [00:02<00:00,  1.05it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:01<00:00,  1.27s/it]\n","                   all          4          8      0.267      0.375      0.236      0.175\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      2/150      2.26G      1.364      3.409      1.482          9        640: 100% 3/3 [00:00<00:00,  6.76it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 18.16it/s]\n","                   all          4          8      0.768      0.125      0.215      0.162\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      3/150      2.29G      1.238      3.394      1.397          8        640: 100% 3/3 [00:00<00:00,  4.57it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  7.38it/s]\n","                   all          4          8      0.696      0.625      0.626      0.554\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      4/150      2.37G     0.9207      2.222      1.139          8        640: 100% 3/3 [00:00<00:00,  4.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.33it/s]\n","                   all          4          8      0.622      0.875      0.709      0.623\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      5/150      2.36G     0.7529      1.807      1.048          7        640: 100% 3/3 [00:00<00:00,  5.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.85it/s]\n","                   all          4          8      0.775      0.875      0.838      0.731\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      6/150      2.36G     0.6178      1.602      1.026          7        640: 100% 3/3 [00:00<00:00,  6.65it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 10.41it/s]\n","                   all          4          8      0.791      0.952      0.971      0.857\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      7/150      2.36G     0.5803       1.32      1.044          7        640: 100% 3/3 [00:00<00:00,  7.55it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 12.06it/s]\n","                   all          4          8          1       0.25      0.535      0.471\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      8/150      2.37G     0.6536      1.213      1.009          9        640: 100% 3/3 [00:00<00:00,  6.38it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 16.18it/s]\n","                   all          4          8      0.396          1      0.748      0.613\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      9/150      2.37G     0.6286      1.065     0.9743         13        640: 100% 3/3 [00:00<00:00,  6.84it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 11.36it/s]\n","                   all          4          8      0.794      0.875      0.904      0.723\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     10/150      2.37G     0.6847      1.261      1.061          6        640: 100% 3/3 [00:00<00:00,  6.64it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.88it/s]\n","                   all          4          8      0.573      0.875      0.671      0.525\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     11/150      2.37G     0.6811      1.202      1.033          9        640: 100% 3/3 [00:00<00:00,  4.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.22it/s]\n","                   all          4          8      0.693      0.625      0.566      0.457\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     12/150      2.37G     0.5805     0.9742     0.9461         11        640: 100% 3/3 [00:00<00:00,  5.06it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  9.26it/s]\n","                   all          4          8      0.471      0.625      0.589      0.478\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     13/150      2.36G     0.7128      1.351      1.095         10        640: 100% 3/3 [00:00<00:00,  6.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 12.15it/s]\n","                   all          4          8          1        0.6      0.644      0.397\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     14/150      2.37G      0.603      1.051     0.9684         11        640: 100% 3/3 [00:00<00:00,  6.72it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 11.76it/s]\n","                   all          4          8      0.547      0.625      0.554      0.421\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     15/150      2.37G     0.6734      1.299     0.9833         10        640: 100% 3/3 [00:00<00:00,  8.35it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 12.37it/s]\n","                   all          4          8      0.547      0.625      0.554      0.421\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     16/150      2.38G     0.7285       1.14     0.9788         16        640: 100% 3/3 [00:00<00:00,  6.72it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  8.96it/s]\n","                   all          4          8      0.529       0.75       0.73      0.575\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     17/150      2.36G     0.7127     0.9443      1.006         10        640: 100% 3/3 [00:00<00:00,  6.75it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 13.03it/s]\n","                   all          4          8       0.55       0.75      0.849      0.696\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     18/150      2.37G     0.7003      1.148      1.084          8        640: 100% 3/3 [00:00<00:00,  8.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  8.51it/s]\n","                   all          4          8       0.55       0.75      0.849      0.696\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     19/150      2.37G     0.8168       1.09      1.131          8        640: 100% 3/3 [00:00<00:00,  4.78it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  7.25it/s]\n","                   all          4          8      0.642        0.9      0.955      0.654\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     20/150      2.37G     0.7697       1.07      1.083         10        640: 100% 3/3 [00:00<00:00,  4.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.45it/s]\n","                   all          4          8      0.561       0.75      0.596      0.339\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     21/150      2.37G     0.6427      1.064      1.004         15        640: 100% 3/3 [00:00<00:00,  5.64it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.17it/s]\n","                   all          4          8      0.561       0.75      0.596      0.339\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     22/150      2.37G     0.8899      1.222      1.128          8        640: 100% 3/3 [00:00<00:00,  6.13it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 10.56it/s]\n","                   all          4          8      0.521      0.625      0.429      0.324\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     23/150      2.37G     0.7561      1.192      1.059          7        640: 100% 3/3 [00:00<00:00,  7.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 12.42it/s]\n","                   all          4          8      0.521      0.625      0.429      0.324\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     24/150      2.37G     0.7755      1.009      1.014         11        640: 100% 3/3 [00:00<00:00,  7.70it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 11.10it/s]\n","                   all          4          8      0.338      0.375      0.367      0.284\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     25/150      2.37G     0.7685      1.081       1.06          7        640: 100% 3/3 [00:00<00:00,  5.54it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 12.60it/s]\n","                   all          4          8      0.338      0.375      0.367      0.284\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     26/150      2.37G     0.8783      1.455      1.235         11        640: 100% 3/3 [00:00<00:00,  6.80it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  7.92it/s]\n","                   all          4          8      0.648        0.5      0.573      0.415\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     27/150      2.37G     0.7858      1.103      1.044         15        640: 100% 3/3 [00:00<00:00,  7.89it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 11.65it/s]\n","                   all          4          8      0.648        0.5      0.573      0.415\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     28/150      2.37G     0.9875        1.5      1.207          6        640: 100% 3/3 [00:00<00:00,  4.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.88it/s]\n","                   all          4          8      0.952        0.5      0.676      0.491\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     29/150      2.37G     0.8482      1.326       1.15         14        640: 100% 3/3 [00:00<00:00,  4.71it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  7.14it/s]\n","                   all          4          8      0.952        0.5      0.676      0.491\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     30/150      2.38G     0.8181      1.354      1.086         10        640: 100% 3/3 [00:00<00:00,  4.62it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.94it/s]\n","                   all          4          8      0.952        0.5      0.676      0.491\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     31/150      2.37G     0.9087      1.129      1.091         13        640: 100% 3/3 [00:00<00:00,  7.64it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 10.45it/s]\n","                   all          4          8      0.774      0.859      0.878      0.677\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     32/150      2.37G     0.9235      1.139      1.202         12        640: 100% 3/3 [00:00<00:00,  7.77it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  9.92it/s]\n","                   all          4          8      0.774      0.859      0.878      0.677\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     33/150      2.37G     0.8766      1.128      1.138         11        640: 100% 3/3 [00:00<00:00,  7.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 14.71it/s]\n","                   all          4          8      0.725      0.988      0.891      0.713\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     34/150      2.36G      0.938      1.226      1.179         12        640: 100% 3/3 [00:00<00:00,  6.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 12.01it/s]\n","                   all          4          8      0.725      0.988      0.891      0.713\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     35/150      2.37G     0.8978      1.014      1.166         10        640: 100% 3/3 [00:00<00:00,  7.62it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 14.34it/s]\n","                   all          4          8      0.725      0.988      0.891      0.713\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     36/150      2.37G     0.7385     0.9729       1.04         14        640: 100% 3/3 [00:00<00:00,  6.41it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 10.29it/s]\n","                   all          4          8      0.978      0.625      0.739      0.532\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     37/150      2.37G     0.7479      1.018      1.037         15        640: 100% 3/3 [00:00<00:00,  8.23it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 11.23it/s]\n","                   all          4          8      0.978      0.625      0.739      0.532\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     38/150      2.37G     0.8665        1.2       1.14         11        640: 100% 3/3 [00:00<00:00,  5.85it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  7.46it/s]\n","                   all          4          8      0.978      0.625      0.739      0.532\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     39/150      2.37G     0.9731      1.426      1.208          7        640: 100% 3/3 [00:00<00:00,  5.11it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.63it/s]\n","                   all          4          8      0.816      0.625      0.597      0.466\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     40/150      2.37G     0.8993      1.173      1.177          9        640: 100% 3/3 [00:00<00:00,  5.48it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 12.44it/s]\n","                   all          4          8      0.816      0.625      0.597      0.466\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     41/150      2.37G     0.9174      1.167      1.137         16        640: 100% 3/3 [00:00<00:00,  4.24it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 11.56it/s]\n","                   all          4          8      0.779      0.625      0.695      0.598\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     42/150      2.36G     0.7994      1.213      1.135         10        640: 100% 3/3 [00:00<00:00,  7.54it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 12.58it/s]\n","                   all          4          8      0.779      0.625      0.695      0.598\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     43/150      2.38G     0.8701      1.399      1.134          9        640: 100% 3/3 [00:00<00:00,  8.23it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 18.94it/s]\n","                   all          4          8      0.779      0.625      0.695      0.598\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     44/150      2.36G     0.9655      1.323      1.197          9        640: 100% 3/3 [00:00<00:00,  6.71it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 12.20it/s]\n","                   all          4          8          1      0.491      0.626      0.563\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     45/150      2.37G      0.981       1.12      1.151         14        640: 100% 3/3 [00:00<00:00,  7.23it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 10.80it/s]\n","                   all          4          8          1      0.491      0.626      0.563\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     46/150      2.37G     0.7988      1.086      1.146          8        640: 100% 3/3 [00:00<00:00,  7.68it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 12.30it/s]\n","                   all          4          8          1      0.491      0.626      0.563\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     47/150      2.37G      1.071      1.461      1.349          8        640: 100% 3/3 [00:00<00:00,  6.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 10.03it/s]\n","                   all          4          8          1       0.25      0.407      0.268\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     48/150      2.37G      1.111      1.665      1.438          5        640: 100% 3/3 [00:00<00:00,  5.24it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  8.31it/s]\n","                   all          4          8          1       0.25      0.407      0.268\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     49/150      2.37G     0.7948      1.347      1.082         14        640: 100% 3/3 [00:00<00:00,  4.22it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 10.01it/s]\n","                   all          4          8       0.42      0.625      0.579      0.438\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     50/150      2.36G     0.9596      1.183      1.224         10        640: 100% 3/3 [00:00<00:00,  5.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  9.37it/s]\n","                   all          4          8       0.42      0.625      0.579      0.438\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     51/150      2.37G     0.8279      1.185      1.122         17        640: 100% 3/3 [00:00<00:00,  8.18it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 11.36it/s]\n","                   all          4          8       0.42      0.625      0.579      0.438\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     52/150      2.37G     0.8136      1.126      1.154         10        640: 100% 3/3 [00:00<00:00,  7.08it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 10.90it/s]\n","                   all          4          8      0.303          1      0.534      0.444\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     53/150      2.36G      1.205      1.934      1.462          3        640: 100% 3/3 [00:00<00:00,  7.72it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 17.26it/s]\n","                   all          4          8      0.303          1      0.534      0.444\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     54/150      2.37G     0.8516      1.163      1.152         15        640: 100% 3/3 [00:00<00:00,  7.10it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 17.80it/s]\n","                   all          4          8      0.303          1      0.534      0.444\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     55/150      2.37G     0.8906      1.219      1.179         11        640: 100% 3/3 [00:00<00:00,  7.21it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  8.61it/s]\n","                   all          4          8       0.75      0.375      0.578      0.423\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     56/150      2.37G     0.9329      1.078      1.146         16        640: 100% 3/3 [00:00<00:00,  7.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 11.27it/s]\n","                   all          4          8       0.75      0.375      0.578      0.423\n","Stopping training early as no improvement observed in last 50 epochs. Best results observed at epoch 6, best model saved as best.pt.\n","To update EarlyStopping(patience=50) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n","\n","56 epochs completed in 0.028 hours.\n","Optimizer stripped from /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/training_results/door_and_window/weights/last.pt, 22.5MB\n","Optimizer stripped from /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/training_results/door_and_window/weights/best.pt, 22.5MB\n","\n","Validating /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/training_results/door_and_window/weights/best.pt...\n","Ultralytics YOLOv8.1.4 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 11126358 parameters, 0 gradients, 28.4 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 12.98it/s]\n","                   all          4          8      0.793      0.961      0.971      0.857\n","                 doors          4          8      0.793      0.961      0.971      0.857\n","Speed: 0.3ms preprocess, 7.1ms inference, 0.0ms loss, 7.0ms postprocess per image\n","Results saved to \u001b[1m/content/drive/MyDrive/Door_and_window/yolov8_pointcloud/training_results/door_and_window\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/train\n"]}]},{"cell_type":"markdown","source":["Inferencing"],"metadata":{"id":"evT9HKbVvdjw"}},{"cell_type":"code","source":["!yolo task=detect mode=predict model=/content/drive/MyDrive/Door_and_window/yolov8_pointcloud/training_results/door_and_window/weights/best.pt conf=0.55 source=/content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images"],"metadata":{"id":"s5J12mJvuD-g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705939852961,"user_tz":-60,"elapsed":24332,"user":{"displayName":"isheanesu mugwagwa","userId":"00412971276279760791"}},"outputId":"85dc4d30-f5da-47bd-fa3b-54764a3602a8"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.1.4 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 11126358 parameters, 0 gradients, 28.4 GFLOPs\n","\n","image 1/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/118_Color.png: 480x640 3 doorss, 133.3ms\n","image 2/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/29_Color.png: 480x640 4 doorss, 13.1ms\n","image 3/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/2_Color.png: 480x640 6 doorss, 13.0ms\n","image 4/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/42_Color.png: 480x640 6 doorss, 13.1ms\n","image 5/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/46_Color.png: 480x640 (no detections), 13.0ms\n","image 6/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/51_Color.png: 480x640 3 doorss, 13.1ms\n","image 7/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/59_Color.png: 480x640 3 doorss, 13.1ms\n","image 8/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/77_Color.png: 480x640 3 doorss, 13.1ms\n","image 9/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/89_Color.png: 480x640 6 doorss, 13.1ms\n","image 10/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/96_Color.png: 480x640 2 doorss, 13.1ms\n","image 11/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/image-26.png: 544x640 13 doorss, 71.2ms\n","image 12/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/image-28.png: 576x640 7 doorss, 79.4ms\n","image 13/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/image-30.png: 640x640 7 doorss, 17.3ms\n","image 14/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/image-33.png: 128x640 4 doorss, 68.6ms\n","image 15/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/image-42.png: 352x640 6 doorss, 71.5ms\n","image 16/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/image-6.png: 352x640 11 doorss, 10.7ms\n","image 17/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/image-62.png: 640x640 7 doorss, 17.2ms\n","image 18/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/image-67.png: 384x640 3 doorss, 128.8ms\n","image 19/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/image-74.png: 640x640 9 doorss, 18.9ms\n","image 20/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/image-76.png: 288x640 8 doorss, 120.7ms\n","image 21/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/image-77.png: 512x640 5 doorss, 123.8ms\n","image 22/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/image-86.png: 224x640 4 doorss, 71.8ms\n","image 23/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/photo_2023-09-22_12-26-12.jpg: 640x480 6 doorss, 82.7ms\n","image 24/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/photo_2023-09-22_12-26-15.jpg: 640x480 3 doorss, 12.2ms\n","image 25/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/photo_2023-09-22_12-26-18.jpg: 640x480 2 doorss, 12.3ms\n","image 26/26 /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/test_images/photo_2023-09-22_12-26-26.jpg: 640x480 2 doorss, 12.3ms\n","Speed: 2.3ms preprocess, 45.0ms inference, 20.8ms postprocess per image at shape (1, 3, 640, 480)\n","Results saved to \u001b[1mruns/detect/predict\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/predict\n"]}]},{"cell_type":"code","source":["!cp -r /content/runs/detect/predict /content/drive/MyDrive/Door_and_window/yolov8_pointcloud/output"],"metadata":{"id":"wjMB2OWAuELR","executionInfo":{"status":"ok","timestamp":1705939968784,"user_tz":-60,"elapsed":8858,"user":{"displayName":"isheanesu mugwagwa","userId":"00412971276279760791"}}},"execution_count":11,"outputs":[]}]}